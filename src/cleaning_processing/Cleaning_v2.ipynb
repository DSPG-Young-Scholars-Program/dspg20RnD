{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import ascii_letters\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextCleaning\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550088, 16)\n"
     ]
    }
   ],
   "source": [
    "# reading in raw data\n",
    "\n",
    "df = pd.read_csv('../../data/original/raw_abstracts.csv',engine='python')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nulls in  ABSTRACT . These rows removed.\n",
      "11 duplicate abstracts removed\n",
      "0 project ID duplicates - not removed\n"
     ]
    }
   ],
   "source": [
    "# this will be handled by Lara's script\n",
    "df = TextCleaning.remove_nulls(df, \"ABSTRACT\")\n",
    "df = TextCleaning.remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# lowercase all abstracts, strip leading and trailing whitespace,\n",
    "# and save in a working abstract column that will be updated as text is cleaned\n",
    "\n",
    "df[\"working_abstract\"] = [abstract.lower().strip() for abstract in df[\"ABSTRACT\"]] \n",
    "df = TextCleaning.drop_empties(df)\n",
    "\n",
    "wa = 'working_abstract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start Char']=df['working_abstract'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>FY</th>\n",
       "      <th>FIRST_CHAR</th>\n",
       "      <th>LAST_CHAR</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>IC_CENTER</th>\n",
       "      <th>PROJECT_NUMBER</th>\n",
       "      <th>PROJECT_TITLE</th>\n",
       "      <th>PROJECT_TERMS</th>\n",
       "      <th>CONTACT_PI_PROJECT_LEADER</th>\n",
       "      <th>OTHER_PIS</th>\n",
       "      <th>ORGANIZATION_NAME</th>\n",
       "      <th>CFDA_CODE</th>\n",
       "      <th>FY_TOTAL_COST</th>\n",
       "      <th>working_abstract</th>\n",
       "      <th>Start Char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89996</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>2008</td>\n",
       "      <td>This is a project to explore Game-based, Metap...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0814512</td>\n",
       "      <td>RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...</td>\n",
       "      <td>Achievement; analog; base; Cognitive Science; ...</td>\n",
       "      <td>REESE, DEBBIE D</td>\n",
       "      <td>CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN</td>\n",
       "      <td>WHEELING JESUIT UNIVERSITY</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1999467.0</td>\n",
       "      <td>this is a project to explore game-based, metap...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89997</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Institution: Franklin Institute Science Museum...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0741659</td>\n",
       "      <td>ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...</td>\n",
       "      <td>Active Learning; Child; Computer software; des...</td>\n",
       "      <td>SNYDER, STEVEN</td>\n",
       "      <td>ELINICH, KAREN; YOON, SUSAN</td>\n",
       "      <td>FRANKLIN INSTITUTE</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1799699.0</td>\n",
       "      <td>institution: franklin institute science museum...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89998</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Through programs (including small group conver...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0813522</td>\n",
       "      <td>BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...</td>\n",
       "      <td>Address; Age; Birth; Brain; Caregivers; Child;...</td>\n",
       "      <td>FINK, LAURIE KLEINBAUM</td>\n",
       "      <td>CADIGAN, KAREN; ELLENBOGEN, KIRSTEN</td>\n",
       "      <td>SCIENCE MUSEUM OF MINNESOTA</td>\n",
       "      <td>47.076</td>\n",
       "      <td>1505858.0</td>\n",
       "      <td>through programs (including small group conver...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89999</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>2008</td>\n",
       "      <td>In partnership with the American Chemical Soci...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0838627</td>\n",
       "      <td>FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...</td>\n",
       "      <td>Advanced Development; American; Chemicals; Che...</td>\n",
       "      <td>JOST, JOHN W</td>\n",
       "      <td>MILLER, BRADLEY; BOWMAN, KATHERINE</td>\n",
       "      <td>INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY</td>\n",
       "      <td>47.049</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>in partnership with the american chemical soci...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Amphibian populations around the world are exp...</td>\n",
       "      <td>.</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NSF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0815315</td>\n",
       "      <td>COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...</td>\n",
       "      <td>Amphibia; Central America; Communicable Diseas...</td>\n",
       "      <td>ZAMUDIO, KELLY R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORNELL UNIVERSITY ITHACA</td>\n",
       "      <td>47.074</td>\n",
       "      <td>370996.0</td>\n",
       "      <td>amphibian populations around the world are exp...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROJECT_ID                                           ABSTRACT    FY  \\\n",
       "0       89996  This is a project to explore Game-based, Metap...  2008   \n",
       "1       89997  Institution: Franklin Institute Science Museum...  2008   \n",
       "2       89998  Through programs (including small group conver...  2008   \n",
       "3       89999  In partnership with the American Chemical Soci...  2008   \n",
       "4       90000  Amphibian populations around the world are exp...  2008   \n",
       "\n",
       "                                          FIRST_CHAR LAST_CHAR DEPARTMENT  \\\n",
       "0  This is a project to explore Game-based, Metap...         .        NSF   \n",
       "1  Institution: Franklin Institute Science Museum...         .        NSF   \n",
       "2  Through programs (including small group conver...         .        NSF   \n",
       "3  In partnership with the American Chemical Soci...         .        NSF   \n",
       "4  Amphibian populations around the world are exp...         .        NSF   \n",
       "\n",
       "  AGENCY IC_CENTER PROJECT_NUMBER  \\\n",
       "0    NSF       NaN        0814512   \n",
       "1    NSF       NaN        0741659   \n",
       "2    NSF       NaN        0813522   \n",
       "3    NSF       NaN        0838627   \n",
       "4    NSF       NaN        0815315   \n",
       "\n",
       "                                       PROJECT_TITLE  \\\n",
       "0  RUI: CYGAMES: CYBER-ENABLED TEACHING AND LEARN...   \n",
       "1  ARIEL - AUGMENTED REALITY FOR INTERPRETIVE AND...   \n",
       "2  BRIGHTER FUTURES: PUBLIC DELIBERATION ABOUT TH...   \n",
       "3  FOSTERING US-INTERNATIONAL COLLABORATIVE PARTN...   \n",
       "4  COLLABORATIVE RESEARCH: EVOLUTION OF AMPHIBIAN...   \n",
       "\n",
       "                                       PROJECT_TERMS  \\\n",
       "0  Achievement; analog; base; Cognitive Science; ...   \n",
       "1  Active Learning; Child; Computer software; des...   \n",
       "2  Address; Age; Birth; Brain; Caregivers; Child;...   \n",
       "3  Advanced Development; American; Chemicals; Che...   \n",
       "4  Amphibia; Central America; Communicable Diseas...   \n",
       "\n",
       "  CONTACT_PI_PROJECT_LEADER                                  OTHER_PIS  \\\n",
       "0           REESE, DEBBIE D  CARTER, BEVERLY; WOOD, CHARLES; HITT, BEN   \n",
       "1            SNYDER, STEVEN                ELINICH, KAREN; YOON, SUSAN   \n",
       "2    FINK, LAURIE KLEINBAUM        CADIGAN, KAREN; ELLENBOGEN, KIRSTEN   \n",
       "3              JOST, JOHN W         MILLER, BRADLEY; BOWMAN, KATHERINE   \n",
       "4          ZAMUDIO, KELLY R                                        NaN   \n",
       "\n",
       "                                   ORGANIZATION_NAME CFDA_CODE  FY_TOTAL_COST  \\\n",
       "0                         WHEELING JESUIT UNIVERSITY    47.076      1999467.0   \n",
       "1                                 FRANKLIN INSTITUTE    47.076      1799699.0   \n",
       "2                        SCIENCE MUSEUM OF MINNESOTA    47.076      1505858.0   \n",
       "3  INTERNATIONAL UNION OF PURE AND APPLIED CHEMISTRY    47.049        51000.0   \n",
       "4                          CORNELL UNIVERSITY ITHACA    47.074       370996.0   \n",
       "\n",
       "                                    working_abstract Start Char  \n",
       "0  this is a project to explore game-based, metap...          t  \n",
       "1  institution: franklin institute science museum...          i  \n",
       "2  through programs (including small group conver...          t  \n",
       "3  in partnership with the american chemical soci...          i  \n",
       "4  amphibian populations around the world are exp...          a  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270 short abstracts removed\n"
     ]
    }
   ],
   "source": [
    "## what do we want to do here???\n",
    "\n",
    "#importlib.reload(TextCleaning)\n",
    "df = TextCleaning.remove_short_abstracts(df,limit=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Strategy:\n",
    "1. Remove abstracts with all non-alphanumeric characters.\n",
    "2. Remove non-alphanumeric characters from the start and end of abstracts\n",
    "3. Remove other non-readable abstracts. (REMOVAL ABSTRACTS FOUND BY INSPECTION)\n",
    "4. Remove \"junk\" starting strings and ending strings\n",
    "5. Remove \"junk\" strings in the middle \n",
    "6. Remove title and organization name from abstracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([92077, 445788, 477487], dtype='int64')\n",
      "dropped 3\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphnum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abstracts that are not readable: THIS NEEDS TO BE UPDATED BY HAND FOR EVERY NEW DATASET\n",
    "# For example: index = 490684: ¢ £/¥ ƒ § ¤ ƒ “ ƒ « ...\n",
    "\n",
    "df[\"Start Char\"] = df['working_abstract'].apply(lambda x: x[0])\n",
    "ix = df[df['Start Char'] == 'ƒ'].index\n",
    "df.drop(index = ix, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 219964,\n",
       " 't': 136215,\n",
       " 'p': 43877,\n",
       " 'a': 29678,\n",
       " 'i': 15636,\n",
       " 's': 12932,\n",
       " 'c': 12292,\n",
       " 'w': 10662,\n",
       " 'o': 9418,\n",
       " 'm': 8505,\n",
       " 'b': 7607,\n",
       " 'n': 6869,\n",
       " 'r': 5585,\n",
       " 'e': 5124,\n",
       " 'f': 4112,\n",
       " 'h': 3793,\n",
       " 'u': 3269,\n",
       " '1': 3232,\n",
       " 'g': 3159,\n",
       " 'l': 2761,\n",
       " '0': 1320,\n",
       " 'v': 1265,\n",
       " 'k': 564,\n",
       " '7': 512,\n",
       " 'j': 437,\n",
       " 'q': 338,\n",
       " '6': 154,\n",
       " 'y': 153,\n",
       " '2': 143,\n",
       " 'x': 109,\n",
       " 'z': 98,\n",
       " '3': 98,\n",
       " '5': 58,\n",
       " '4': 48,\n",
       " '9': 46,\n",
       " '8': 33,\n",
       " 'α': 1,\n",
       " 'β': 1,\n",
       " 'γ': 1,\n",
       " 'δ': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df[\"Start Char\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"junk\" phrases at start to remove\n",
    "\n",
    "start_phrases=['abstract', 'summary', 'proposal', 'description', 'narrative', \n",
    "               'technical abstract',\n",
    "               'non technical abstract', \n",
    "               'non- technical abstract',\n",
    "               'non-technical abstract',                      \n",
    "               'nontechnical abstract',\n",
    "               'technical summary', \n",
    "               'nontechnical summary',\n",
    "               'non-technical summary',\n",
    "               'non-technical description',\n",
    "               'description (provided by the applicant)',\n",
    "               'description (provided by investigator)',  \n",
    "               'description (provided by applicant)',\n",
    "               'project summary/abstract',\n",
    "               'proposal abstract',\n",
    "               'research abstract',\n",
    "               'project summary',\n",
    "               'research summary',\n",
    "               'project description'\n",
    "               'see instructions):',\n",
    "               'for center application (provided by the investigator):',\n",
    "               'objective(s)',      \n",
    "               'exceed the space provided',\n",
    "               'provided by applicant',\n",
    "               'provided by candidate']\n",
    "                \n",
    " # [hrd #######]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([86769, 188021, 262748, 437435, 438719, 453984], dtype='int64')\n",
      "dropped 6\n"
     ]
    }
   ],
   "source": [
    "#Remove found start phrases\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start']) \n",
    "\n",
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeated start phrase removal in case the order of project summary/abstract varies\n",
    "\n",
    "for phrase in start_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'Start'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_exact_phrases to remove\n",
    "\n",
    "#'This subproject represents an estimate of the percentage of the CTSA funding that isbeing utilized for a broad area of research (AIDS research, pediatric research, orclinical trials).  The Total Cost listed is only an estimate of the amount of CTSAinfrastructure going towards this area of research, not direct funding provided bythe NCRR grant to the subproject or subproject staff.'\n",
    "#'This subproject is one of many research subprojects utilizing theresources provided by a Center grant funded by NIH/NCRR. The subproject andinvestigator (PI) may have received primary funding from another NIH source,and thus could be represented in other CRISP entries. The institution listed isfor the Center, which is not necessarily the institution for the investigator.'\n",
    "\n",
    "df[wa]=df[wa].apply(lambda x: x.replace('this subproject represents an estimate of the percentage of the ctsa funding that isbeing utilized for a broad area of research (aids research, pediatric research, orclinical trials).  the total cost listed is only an estimate of the amount of ctsainfrastructure going towards this area of research, not direct funding provided bythe ncrr grant to the subproject or subproject staff.',\n",
    "                                       ''))\n",
    "\n",
    "expression=re.compile('this subproject is one of many research subprojects.*not necessarily the institution for the investigator.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('this subproject is one of many research subprojects.*to the subproject or subproject staff.')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([34372, 405975], dtype='int64')\n",
      "dropped 2\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphnum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)\n",
    "    \n",
    "# update Start Char column in df\n",
    "df['Start Char']=df[wa].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_phrases = ['(end of abstract',\n",
    "               'end of abstract', \n",
    "               '(abstract end',  \n",
    "               '(end of abstract',\n",
    "               '(end 0f abstract',\n",
    "               '(end of absract',\n",
    "               '(abstract below',\n",
    "               '(end of reviewers\\' comment',\n",
    "               '(end abstract',\n",
    "               'performance site ========================================section end',\n",
    "               'key personnel ========================================section end',\n",
    "               '[summary truncated at 7800 characters', \n",
    "               'this award reflects nsf\\'s statutory mission and has been deemed worthy of support through evaluation using the foundation\\'s intellectual merit and broader impacts review criteria',\n",
    "               'project description page 6', 'page 1 of 1', 'project summary/abstract page 6',\n",
    "               'project description page 7', 'project summary/abstract page 7', 'pag 1 o 1', \n",
    "               'page 2 number pages consecutively at the bottom throughout form page 2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "dropped 0\n"
     ]
    }
   ],
   "source": [
    "# end phrase removal\n",
    "\n",
    "for phrase in end_phrases:\n",
    "    df[wa]=df[wa].apply(TextCleaning.remove_phrase,args=[phrase,'End'])  \n",
    "\n",
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)\n",
    "    \n",
    "# update Last Char column in df\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"junk\" removal within text body - not necessarily at the start or end\n",
    "\n",
    "# 1. 'Enter the text here that' ending with 'lines of text.'\n",
    "expression=re.compile('enter the text here that.*lines of text')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('phs .*?continuation format page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "expression=re.compile('omb no .*?continuation format page')\n",
    "df[wa]=df[wa].apply(lambda x: re.sub(expression,'',x))\n",
    "\n",
    "df[wa]=df[wa].replace('project summary/abstract','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If it starts with 'one page and must contain',\n",
    "This is an NIH thing and there aren't that many of them, but come from 3 different cfda\n",
    "it will start with \"one page and must contain a summary of the proposed activity suitable for dissemination to thepublic. \n",
    "It should be a self-contained description of the project and should contain a statement of objectives and methods to be employed.\n",
    "It should be informative to other persons working in the same or related fields and insofar as possible understandable to a technically liter-ate lay reader. \n",
    "This Abstract must not include any proprietary/confidential information.* \n",
    "Please click the add attachment button to complete this entry.\" plus some attachments, which includes tracking number, twice:\n",
    "following the second trackign number, there is a grant number followed by the actual content\" \n",
    "\n",
    "At the end of these files, they all end in 'Project Narrative File'(last instance) followed by more attachments, all of which can be discarded\n",
    "\"\"\"\n",
    "expression1=re.compile('one page and must.*?tracking number.*?(tracking number)')\n",
    "expression2=re.compile('project narrative file.*')\n",
    "\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('one page and must contain'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "df[wa]=df[wa].apply(fix_abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of phrase at end or beginning?\n",
    "\n",
    "expression=re.compile('project summary/abstract page.*')\n",
    "\n",
    "def remove_contact_pd(x):\n",
    "    \n",
    "    # removes clause at end that tends to occur: eg Project Summary/Abstract Page 222Contact PD/PI: Sampson, HughNarrative (\n",
    "    \n",
    "    if x.startswith('Contact PD/PI'):\n",
    "        return re.sub(expression,'',x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df[wa]=df[wa].apply(remove_contact_pd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([376319], dtype='int64')\n",
      "dropped 1\n"
     ]
    }
   ],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_title_org(record):\n",
    "    \n",
    "    # This function removes project titles and organization names from abstracts\n",
    "    \n",
    "    \"\"\" ignores case to remove multi-word phrases in a particular order, especially those likely to run into other words,\n",
    "    e.g. Institution university of washingtonPI mary williams. This doesn't work when titles or insititutions have escape characters in them, which is a bummer\n",
    "    see for example ENHANCING THE USE OF NASA EARTH SCIENCE RESULTS / DATA / AND TECHNOLOGY BY ENGAGING THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS COMMUNITIES OF\n",
    "    PRACTICE IN TARGET AREAS OF INTEREST TO NASA THE FEDERATION OF EARTH SCIENCE INFORMATION PARTNERS (''FED\"\"\"\n",
    "    \n",
    "    title=record['PROJECT_TITLE']\n",
    "    \n",
    "    try:\n",
    "        new_abstract=re.sub(title,'',record[wa],flags=re.IGNORECASE)      \n",
    "        return re.sub(record['ORGANIZATION_NAME'],'',new_abstract,flags=re.IGNORECASE)   \n",
    "    except:\n",
    "        try:\n",
    "            return re.sub(record['ORGANIZATION_NAME'],'',record[wa],flags=re.IGNORECASE)   \n",
    "        except:\n",
    "            return record[wa]\n",
    "        \n",
    "        \n",
    "df[wa]=df.apply(lambda x: remove_title_org(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_custom_words(record,col_to_clean):\n",
    "    \"\"\"Designates stopwords for a particular abstract that contain embedded info e.g. author names and removes them from a lowercase abstract\"\"\"\n",
    "    fields_to_replace=[]\n",
    "    if type(record[col_to_clean])!=list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        #Main PI\n",
    "        #Adds all words in the pis names, excluding initials (hence why the commas and periods must be replaced)\n",
    "        if pd.notnull(record['CONTACT_PI_PROJECT_LEADER']):\n",
    "            fields_to_replace.extend([x.lower() for x in record['CONTACT_PI_PROJECT_LEADER'].replace(',','').replace('.','').replace('-',' ').split() if len(x)>1])\n",
    "        #Additional PIs\n",
    "        #For each pi, which are split by semicolons, and format is last,first;  #Sometimes a middle initial\n",
    "        if pd.notnull(record['OTHER_PIS']):\n",
    "            for i in record['OTHER_PIS'].split(';'):\n",
    "                i=i.strip() #Remove whitespace\n",
    "                i=i.replace('.','')#Periods for initials\n",
    "                i=i.replace(',','')#Commas between last, first\n",
    "                i=i.replace('-',' ')#Remove hyphen in hypenated names to make separate words once tokens.\n",
    "                fields_to_replace.extend([x.lower().strip() for x in i.split() if len(x)>1])\n",
    "        return [x.lower() for x in record[col_to_clean] if not x.lower() in fields_to_replace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip non-alphanum characters from the beginning and end of each abstract\n",
    "\n",
    "df[\"working_abstract\"] = [TextCleaning.strip_nonalnum(abstract) for abstract in df[\"working_abstract\"]]\n",
    "df = TextCleaning.drop_empties(df)\n",
    "\n",
    "df['Start Char']=df[wa].apply(lambda x:x[0])\n",
    "df['LAST_CHAR']=df[wa].apply(lambda x:x[-1])\n",
    "df['nchar']=df[wa].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./clean_data_7-7-20.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RUNNING THIS\n",
    "\n",
    "#####################\n",
    "#Additional expressions we could choose to remove\n",
    "#Identify abstracts with excessive amounts of other fields to uncover additional bad abstract types\n",
    "#If we wanted to be on the safe side, some EDA makes me think we could remove anything with more than \n",
    "# 3 or 4 of these fields. It's where they start getting wonky.\n",
    "###################\n",
    "\n",
    "fields=['Principal Investigator','Program Director','Attachment','Instructions','Lines',\n",
    "        'Space Provided','Performance Site','Organization','Key Personnel']\n",
    "all_fields=fields.copy()\n",
    "all_fields.extend([x.lower() for x in fields])\n",
    "all_fields.extend([x.upper() for x in fields])\n",
    "all_fields.extend(['PI','Form','Page','Title','.pdf','.doc'])\n",
    "\n",
    "def count_up_fields(abstract):\n",
    "    count=0\n",
    "    for field in all_fields:\n",
    "        if field in abstract:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "df['Field Count']=df[wa].apply(count_up_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RUNNING THIS\n",
    "\n",
    "###########################\n",
    "#Additional expressions we could remove, but there is a small possibility of some information being lost\n",
    "##########################\n",
    "\n",
    "#Issues: 'Close FormNextPrint PageAbout OMB Number']#This is usually ended with \"Project summary\", \n",
    "#so anything between those 2 can be delete, and #ended with a clause starting with 'Close FormProject' and ending in'Narrative File'\n",
    "\n",
    "#expression1=re.compile('Close FormNext.*?Project Summary')\n",
    "#expression2=re.compile('Close FormProject.*Narrative File')\n",
    "\n",
    "def fix_abstract(abstract):\n",
    "    if abstract.startswith('Close FormNext'):\n",
    "        abstract=re.sub(expression1,'',abstract)\n",
    "        return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "\n",
    "#df[wa]=df[wa].apply(fix_abstract)\n",
    "\n",
    "#If ends in 'Description,', then go to last instance of PERFORMANCE (for Performance SITES), otherwise \"KEY PERSONNEL\", upper case, and cut all that follows\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Description,$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Description,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n",
    "#expression1=re.compile('PERFORMANCE.*Page 3$')\n",
    "#expression2=re.compile('KEY PERSONNEL.*Page 3,$')\n",
    "\n",
    "def apply_expressions(abstract):\n",
    "    if abstract.endswith('Description,'):\n",
    "        if re.search(expression1,abstract) != None:\n",
    "            return re.sub(expression1,'',abstract)\n",
    "        else:\n",
    "            return re.sub(expression2,'',abstract)\n",
    "    else:\n",
    "        return abstract\n",
    "    \n",
    "#df[wa]=df[wa].apply(apply_expressions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
